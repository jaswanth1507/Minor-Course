{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial-1\n",
        "Preprocessing"
      ],
      "metadata": {
        "id": "mbcmgPYV621z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTl4vJF54vRu",
        "outputId": "b71e8fb0-b611-402a-f9c4-22752c04aab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     species\n",
            "22         0\n",
            "15         0\n",
            "65         1\n",
            "11         0\n",
            "42         0\n",
            "..       ...\n",
            "71         1\n",
            "106        2\n",
            "14         0\n",
            "92         1\n",
            "102        2\n",
            "\n",
            "[120 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.DataFrame(iris.target, columns=['species'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# X_train, X_test, y_train, and y_test are now ready for machine learning modeling.\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial-2"
      ],
      "metadata": {
        "id": "wD7D99q_9cpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the California housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "X = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "y = california_housing.target\n",
        "X = X[['MedInc']]\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjRffbPs7pg8",
        "outputId": "74d269fa-d5e2-421d-9805-9e5fa9a79da9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 0.8420901241414455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial-3"
      ],
      "metadata": {
        "id": "Bg_pB12r-Maa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "k_folds = KFold(n_splits = 5)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = k_folds)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B39ceotk-OUG",
        "outputId": "93fc28ba-34cb-477f-ea51-e7c560ee9198"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [1.         1.         0.83333333 0.93333333 0.8       ]\n",
            "Average CV Score:  0.9133333333333333\n",
            "Number of CV Scores used in Average:  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial-4\n"
      ],
      "metadata": {
        "id": "cgwBjYQt-Rj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate the MSE using the probabilities for a more nuanced regression-like metric on a classification problem\n",
        "mse = mean_squared_error(y_test, y_pred_proba)\n",
        "\n",
        "# Calculate other classification metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZZDXKjQ-ThR",
        "outputId": "df632989-ae02-46da-e54f-07d8c47863d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.0254\n",
            "Accuracy: 0.9561\n",
            "Confusion Matrix:\n",
            "[[39  4]\n",
            " [ 1 70]]\n",
            "Precision: 0.9459\n",
            "Recall: 0.9859\n",
            "F1-Score: 0.9655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial-5"
      ],
      "metadata": {
        "id": "ti_-p-P__f4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "california = fetch_california_housing()\n",
        "X = california.data\n",
        "y = california.target\n",
        "cali_df = pd.DataFrame()\n",
        "print(cali_df.head())\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Coefficients: {model.coef_}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgZQ4PRF_i1o",
        "outputId": "a8fe9532-6349-4080-adc6-49e7957d827b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "Coefficients: [ 4.45822565e-01  9.68186799e-03 -1.22095112e-01  7.78599557e-01\n",
            " -7.75740400e-07 -3.37002667e-03 -4.18536747e-01 -4.33687976e-01]\n",
            "Intercept: -37.05624133152496\n",
            "Mean Squared Error (MSE): 0.5305677824766757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial-6"
      ],
      "metadata": {
        "id": "2keD3pyaBeo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target != 0) * 1\n",
        "iris_df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "print(iris_df.head())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFYXbwLuBdwM",
        "outputId": "d497744b-2877-4061-d2a7-0682417b6880"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "Accuracy: 1.0000\n",
            "Confusion Matrix:\n",
            "[[10  0]\n",
            " [ 0 20]]\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KS_3eUaVCwxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}